{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.load(\"train_points.npy\")  # shape: [B, N, 3]\n",
    "y_train = np.load(\"train_labels.npy\")\n",
    "X_test = np.load(\"test_points.npy\")\n",
    "y_test = np.load(\"test_labels.npy\")\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Test:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_toilet(points):\n",
    "    # 随机绕 z 轴旋转 \n",
    "    theta = np.random.uniform(0, 2 * np.pi)\n",
    "    rot_matrix = np.array([\n",
    "        [np.cos(theta), -np.sin(theta), 0],\n",
    "        [np.sin(theta),  np.cos(theta), 0],\n",
    "        [0,              0,             1]\n",
    "    ])\n",
    "    # 随机高斯噪声\n",
    "    points = points @ rot_matrix.T\n",
    "    points += np.random.normal(0, 0.01, size=points.shape)\n",
    "    return points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "import torch\n",
    "import torch_cluster\n",
    "\n",
    "def to_graph_data(X, y, k=20):\n",
    "    from torch_geometric.nn import knn_graph\n",
    "    data_list = []\n",
    "    for i in range(len(X)):\n",
    "        pc = X[i]\n",
    "        label = int(y[i])\n",
    "        pos = torch.tensor(pc, dtype=torch.float)\n",
    "        edge_index = knn_graph(pos, k=k, loop=False)\n",
    "        data = Data(pos=pos, edge_index=edge_index, y=torch.tensor(label, dtype=torch.long))\n",
    "        data_list.append(data)\n",
    "    return data_list\n",
    "\n",
    "\n",
    "\n",
    "train_data_list = to_graph_data(X_train, y_train, k=20)\n",
    "test_data_list = to_graph_data(X_test, y_test, k=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_data_list, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data_list, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import EdgeConv, global_max_pool\n",
    "\n",
    "class DGCNN(nn.Module):\n",
    "    def __init__(self, k=20, emb_dims=1024, num_classes=10):\n",
    "        super(DGCNN, self).__init__()\n",
    "        self.k = k\n",
    "        self.conv1 = EdgeConv(nn.Sequential(nn.Linear(6, 64), nn.ReLU(), nn.Linear(64, 64)))\n",
    "        self.conv2 = EdgeConv(nn.Sequential(nn.Linear(128, 64), nn.ReLU(), nn.Linear(64, 64)))\n",
    "        self.conv3 = EdgeConv(nn.Sequential(nn.Linear(128, 64), nn.ReLU(), nn.Linear(64, 64)))\n",
    "        self.conv4 = EdgeConv(nn.Sequential(nn.Linear(128, 128), nn.ReLU(), nn.Linear(128, 128)))\n",
    "\n",
    "        self.lin1 = nn.Linear(320, emb_dims)\n",
    "        self.bn1 = nn.BatchNorm1d(emb_dims)\n",
    "        self.dp1 = nn.Dropout(p=0.5)\n",
    "        self.fc1 = nn.Linear(emb_dims, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.pos, data.edge_index, data.batch\n",
    "        x1 = self.conv1(x, edge_index)\n",
    "        x2 = self.conv2(x1, edge_index)\n",
    "        x3 = self.conv3(x2, edge_index)\n",
    "        x4 = self.conv4(x3, edge_index)\n",
    "        x_cat = torch.cat((x1, x2, x3, x4), dim=1)\n",
    "        x = F.relu(self.bn1(self.lin1(x_cat)))\n",
    "        x = global_max_pool(x, batch)\n",
    "        x = self.dp1(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def extract_features(self, data):\n",
    "        x, edge_index, batch = data.pos, data.edge_index, data.batch\n",
    "        x1 = self.conv1(x, edge_index)\n",
    "        x2 = self.conv2(x1, edge_index)\n",
    "        x3 = self.conv3(x2, edge_index)\n",
    "        x4 = self.conv4(x3, edge_index)\n",
    "        x_cat = torch.cat((x1, x2, x3, x4), dim=1)\n",
    "        x = self.bn1(self.lin1(x_cat))\n",
    "        x = global_max_pool(x, batch)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个辅助函数：计算每类准确率（在评估阶段使用）\n",
    "def compute_class_stats(model, loader, device, num_classes):\n",
    "    model.eval()\n",
    "    correct = [0] * num_classes\n",
    "    total = [0] * num_classes\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data)\n",
    "            pred = out.argmax(dim=1)\n",
    "            label = data.y\n",
    "            for i in range(len(label)):\n",
    "                total[label[i]] += 1\n",
    "                if pred[i] == label[i]:\n",
    "                    correct[label[i]] += 1\n",
    "\n",
    "    return correct, total\n",
    "\n",
    "# 定义动态类别权重计算函数\n",
    "def compute_dynamic_weights(correct, total, epsilon=1e-6, alpha=0.3):\n",
    "    acc = [c / (t + epsilon) for c, t in zip(correct, total)]\n",
    "    inv_acc = [1.0 / max(a + 1e-3, 0.01) for a in acc]  # 限制最大值\n",
    "    norm = sum(inv_acc)\n",
    "    dynamic_weights = [w / norm for w in inv_acc]\n",
    "\n",
    "    # 与均匀权重做插值（平滑）\n",
    "    base = 1.0 / len(acc)\n",
    "    weights = [(1 - alpha) * base + alpha * w for w in dynamic_weights]\n",
    "    return torch.tensor(weights, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, weight=None, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight  # Tensor of shape [num_classes]\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        \"\"\"\n",
    "        input: [B, C] — logits\n",
    "        target: [B] — int64 labels\n",
    "        \"\"\"\n",
    "        logp = F.log_softmax(input, dim=1)        # [B, C]\n",
    "        p = torch.exp(logp)                       # [B, C]\n",
    "        focal = (1 - p) ** self.gamma              # [B, C]\n",
    "        loss = -focal * logp                       # [B, C]\n",
    "\n",
    "        # ⚠ 安全方式获取每个样本的类别权重\n",
    "        if self.weight is not None:\n",
    "            w = self.weight.gather(0, target)      # [B]\n",
    "            loss = loss * w.unsqueeze(1)           # broadcast to [B, C]\n",
    "\n",
    "        loss = loss[range(len(target)), target]    # pick per-sample loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss  # [B]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化 loss 函数\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "weights = torch.ones(10)\n",
    "loss_fn = FocalLoss(gamma=2.0, weight=weights.to(device))\n",
    "\n",
    "def train(model, loader, optimizer, device, loss_fn):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = loss_fn(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "def test(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += int((pred == data.y).sum())\n",
    "    return correct / len(loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_tsne(model, loader, device):\n",
    "    model.eval()\n",
    "    features, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            x = model.extract_features(data)\n",
    "            features.append(x.cpu())\n",
    "            labels.append(data.y.cpu())\n",
    "    features = torch.cat(features).numpy()\n",
    "    labels = torch.cat(labels).numpy()\n",
    "\n",
    "    tsne = TSNE(n_components=2, init='pca').fit_transform(features)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(tsne[:, 0], tsne[:, 1], c=labels, cmap='tab10', s=10)\n",
    "    plt.title(\"t-SNE of DGCNN Global Features\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = DGCNN(k=20, num_classes=len(set(y_train))).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(1, 31):\n",
    "    correct, total = compute_class_stats(model, train_loader, device, 10)\n",
    "    weights = compute_dynamic_weights(correct, total).to(device)\n",
    "    loss_fn = FocalLoss(gamma=2.0, weight=weights)\n",
    "\n",
    "    train_loss = train(model, train_loader, optimizer, device, loss_fn)\n",
    "    test_acc = test(model, test_loader, device)\n",
    "    print(f\"Epoch {epoch:02d} | Loss: {train_loss:.4f} | Test Acc: {test_acc:.2%} | Weights: {weights.cpu().numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne(model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def plot_point_cloud(points, label=None, title=\"Point Cloud\", color='b'):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(points[:,0], points[:,1], points[:,2], c=color, s=2)\n",
    "    ax.set_title(f\"{title} - Label: {label}\")\n",
    "    plt.show()\n",
    "\n",
    "plot_point_cloud(X_test[1], label=y_test[0], title=\"Ground Truth\", color='g')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data)\n",
    "        preds = out.argmax(dim=1)\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_labels.append(data.y.cpu())\n",
    "\n",
    "y_pred = torch.cat(all_preds)\n",
    "y_test = torch.cat(all_labels)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"✅ Test Accuracy: {acc:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def per_class_accuracy(y_true, y_pred, class_names=None):\n",
    "    classes = np.unique(y_true)\n",
    "    for cls in classes:\n",
    "        idx = y_true == cls\n",
    "        correct = (y_pred[idx] == cls).sum()\n",
    "        total = idx.sum()\n",
    "        acc = correct / total\n",
    "        label = class_names[cls] if class_names else str(cls)\n",
    "        print(f\"Class {label}: {acc:.2%}\")\n",
    "class_names = [\"chair\", \"table\", \"sofa\", \"bed\", \"desk\", \"dresser\", \"monitor\", \"night_stand\", \"toilet\", \"bathtub\"]  # 举例\n",
    "\n",
    "per_class_accuracy(y_test, y_pred, class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
